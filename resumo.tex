\begin{resumo}
	
Este trabalho avalia a qualidade de itens e da prova de um simulado de Ciências Humanas por meio da Teoria Clássica dos Testes (TCT) e da Teoria de Resposta ao Item (TRI). A prova foi composta por 30 itens provenientes de instituições públicas e privadas, respondida por 664 pessoas. Foram analisadas apenas respostas de indivíduos que responderam todos os itens. Na análise pela TCT, foi obtido um coeficiente alfa de Cronbach igual de 0,744, indicando boa consistência interna do teste, a análise também apontou 7 itens com correlação ponto bisserial abaixo de 0,30.  Na TRI, foram ajustados modelos logísticos de 1, 2 e 3 parâmetros (1PL, 2PL e 3PL) e o modelo unidimensional de 3 parâmetros apresentou melhor ajuste. A comparação entre os modelos utilizando o teste de razão de verossimilhança. A qualidade do ajuste foi avaliada com o índice M$_2$, que demonstrou um bom ajuste,  enquanto os índices RMSEA$_2$, TLI e CFI também indicaram boa adequação do modelo. Na análise dos parâmetros TRI dois itens apresentaram discriminação negativa, indicando problemas. Na investigação, um item havia sido corrigido errado no gabarito e o outro estava mal elaborado, levando o leitor desatento a marcar uma alternativa incorreta. A contribuição de vários itens para a informação da habilidade medida foi praticamente nula, pois para muitos a informação máxima foi próxima de zero. A prova apresentou maior informação para valores baixos de habilidade, sendo que, a habilidade estimada dos examinados foram em sua maioria, medianas e altas.

\textbf{Palavras-chave}: Construção de avaliação, Qualidade de prova, Validação de questionário.
\end{resumo}

\begin{resumo}[Abstract]
 \begin{otherlanguage*}{english}
   This study evaluates the quality of items and the overall structure of a Humanities simulation test through Classical Test Theory (CTT) and Item Response Theory (IRT). The test consisted of 30 items from public and private institutions and was answered by 664 participants. Only responses from individuals who completed all items were analyzed. In the CTT analysis, a Cronbach's alpha coefficient of 0.744 was obtained, indicating good internal consistency of the test; the analysis also identified 7 items with point-biserial correlations below 0.30. In the IRT analysis, 1-, 2-, and 3-parameter logistic models (1PL, 2PL, and 3PL) were fitted, and the unidimensional 3-parameter model showed the best fit. Model comparison was conducted using the likelihood ratio test. The fit quality was evaluated with the M$_2$ index, which demonstrated a good fit, while the RMSEA$_2$, TLI, and CFI indices also indicated good model adequacy. In the analysis of the IRT parameters, two items showed negative discrimination, indicating problems. Upon investigation, one item was found to have an incorrect answer key, and the other was poorly constructed, leading inattentive readers to select an incorrect answer. Several items contributed almost no information about the measured skill, as for many, the maximum information was close to zero. The test provided more information for low skill levels, with most estimated examinee abilities being moderate to high.

   %\vspace{\onelineskip}

   \noindent
   \textbf{Keywords}: Assessment development, Test quality, Questionnaire validation.
 \end{otherlanguage*}
\end{resumo}